{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest = pd.read_csv(\"Arrest_Data_from_2010_to_Present.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest['date'] = pd.to_datetime(arrest['Arrest Date'])\n",
    "arrest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_2018 = arrest[(arrest['date'] >= '01/01/2018') & (arrest['date'] < '01/01/2019')]\n",
    "len(arrest_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_sub_1 = arrest_2018[(arrest_2018['Charge Group Description'] == 'Vehicle Theft') | (arrest_2018['Charge Group Description'] == 'Robbery') | (arrest_2018['Charge Group Description'] == 'Burglary') | (arrest_2018['Charge Group Description'] == 'Receive Stolen Property')]\n",
    "\n",
    "print(arrest_sub_1['Age'].describe())\n",
    "print(np.quantile(arrest_sub_1['Age'], .75))\n",
    "print(np.quantile(arrest_sub_1['Age'], .95))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_2018.groupby('Area ID')['Report ID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10951+7345+5927+3590+3875+9715+2467+2687+6193+3562+3452+6259+5427+6778+4947+3006+3146+3601+4357+3898+3094"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_2018[arrest_2018['Area ID'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_2018['Charge Group Description'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_sub_2 = arrest_2018[(arrest_2018['Charge Group Description'] != 'Non-Criminal Detention') & (arrest_2018['Charge Group Description'] != 'Pre-Delinquency')]\n",
    "\n",
    "arrest_sub_2 = arrest_sub_2.dropna(subset=['Charge Group Description']) \n",
    "\n",
    "arrest_sub_2['Charge Group Description'].unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zscore = lambda x: abs((x - x.mean()) / x.std())\n",
    "arrest_sub_2['z score'] = arrest_sub_2.groupby(['Charge Group Description'])['Age'].transform(zscore)\n",
    "arrest_sub_2.groupby(['Charge Group Description'])['z score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = arrest_sub_2.groupby('Charge Group Description')['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_mean = arrest_sub_2['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sd = arrest_sub_2.groupby('Charge Group Description')['Age'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (sample_mean - pop_mean)/sample_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(z).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest['year'] = arrest['date'].dt.year\n",
    "arrest_felony = arrest[arrest['Arrest Type Code'] == 'F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "felony_2010_2018 = arrest_felony[(arrest_felony['date'] >= '01/01/2010') & (arrest_felony['date'] < '01/01/2019')]\n",
    "\n",
    "counts = felony_2010_2018.groupby(['year'])['Report ID'].count().values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array(range(2010,2019)).reshape(-1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(c, counts)\n",
    "print(regressor.intercept_)\n",
    "print(regressor.coef_)\n",
    "\n",
    "print(regressor.intercept_ + regressor.coef_ * 2019)\n",
    "count_pred = c * regressor.coef_ + regressor.intercept_\n",
    "\n",
    "plt.plot(c, count_pred, '-r')\n",
    "plt.scatter(c, counts, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrest_by_location = arrest.dropna(subset=['Location']) \n",
    "lat_lon = arrest_by_location['Location'].str.split(',', expand=True)\n",
    "\n",
    "lats = lat_lon[0].str.replace('(','').values.reshape(-1)\n",
    "lons = lat_lon[1].str.replace(')','')\n",
    "lons = lons.str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = lats.astype(float)\n",
    "lons = lons.astype(float)\n",
    "\n",
    "arrest_by_location['lats'] = lats\n",
    "arrest_by_location['lons'] = lons\n",
    "print(len(arrest_by_location))\n",
    "\n",
    "arrest_by_location = arrest_by_location[arrest_by_location['lats'] != 0.0]\n",
    "print(len(arrest_by_location))\n",
    "arrest_by_location = arrest_by_location[arrest_by_location['lons'] != 0.0]\n",
    "print(len(arrest_by_location))\n",
    "arrest_by_location = arrest_by_location.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(lat1,lon1,lat2,lon2):\n",
    "    R = 6371\n",
    "    lat1 = (math.pi/180) * lat1\n",
    "    lon1 = (math.pi/180) * lon1\n",
    "    lat2 = (math.pi/180) * lat2\n",
    "    lon2 = (math.pi/180) * lon2\n",
    "    delta_lat = lat2 - lat1\n",
    "    delta_lon = lon2 - lon1\n",
    "    mean_lat = (lat1 + lat2)/2\n",
    "    return R * math.sqrt(delta_lat ** 2 + (math.cos(mean_lat) * delta_lon) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance(34.050536, -118.247861, 33.9543, -118.2827)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat1 = 34.050536\n",
    "lon1 = -118.247861\n",
    "s=[]\n",
    "for i in range(0,len(arrest_by_location)+1):\n",
    "    s.append(distance(lat1,lon1,arrest_by_location['lats'][i],arrest_by_location['lons'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(s))\n",
    "s = np.sort(s)\n",
    "print(len(s[s<=2.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFileIn = open(\"may12pub.dat\", \"r\")\n",
    "DataList = DataFileIn.readlines()\n",
    "DataList.sort()\n",
    "DataFileIn.close()\n",
    "DataTextOut = open('may12pub.txt', 'w')\n",
    "DataTextOut.writelines(DataList) # Write a sequence of strings to a file\n",
    "DataTextOut.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slices(s, *args):\n",
    "    position = 0\n",
    "    for length in args:\n",
    "        yield s[position:position + length]\n",
    "        position += length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "txtfile = open(\"may12pub.dat\",\"r\")\n",
    "arr = []\n",
    "for line in txtfile:\n",
    "    arr.append(list(slices(line, 15,2,4,2,3,2,2,2,2,2,2,2,2,2,2,10,2,2,2,2,2,2,2,5,3,2,2,2,2,2,2,2,2,1,5,3,1,1,1,1,3,3,2,2,2,2,2,2,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,2,2,2,2,2,2,2,2,2,2,3,2,5,2,2,2,2,2,2,2,2,2,2,2,2,2,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,2,2,2,2,2,2,2,2,2,2,2,2,2,6,2,2,6,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,4,4,4,4,1,2,8,1,4,8,8,1,2,2,2,2,2,2,2,2,2,2,2,2,2,10,10,10,10,10,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,4,2,2,2,2,2,2,2,2,2,2,2,2,5,2,2,2,2,2,2,2,2,2,2,2,2,2,10,4,4,4,4,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,17,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disability = pd.DataFrame(arr)\n",
    "disability.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = disability[84].astype(int)\n",
    "status = np.where(status == -1, 1, status)\n",
    "status = np.where(status == -2, 2, status)\n",
    "status = np.where(status == -3, 3, status)\n",
    "status = np.where(status == 2, 0, status)\n",
    "\n",
    "unique, counts = np.unique(status, return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)\n",
    "\n",
    "disability['status'] = status\n",
    "disability = disability[disability['status'] != 3]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_orig = disability\n",
    "\n",
    "#dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "dataset_orig_train, dataset_orig_test = train_test_split(dataset_orig, test_size=0.3, random_state=42)\n",
    "\n",
    "privileged_groups = [{'status': 0}] # No disability\n",
    "unprivileged_groups = [{'status': 1}] # Disability\n",
    "\n",
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train,unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_orig = disability\n",
    "\n",
    "#dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)\n",
    "dataset_orig_train, dataset_orig_test = train_test_split(dataset_orig, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_orig_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_disability = []\n",
    "for i in range(len(disability)):\n",
    "    new_disability.append(pd.to_numeric(disability.iloc[i],errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(new_disability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:, (data.columns != 'status') & (data.columns != 84)& (data.columns != 0)& (data.columns != 1)& (data.columns != 2)]\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "print()\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "pca.fit(X_scaled)\n",
    "X_pca = pca.transform(X_scaled) @ pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_pca)\n",
    "df['target'] = pd.Series(y)\n",
    "\n",
    "fig = px.scatter_3d(df, x=121, y=81, z=251,color='target')  # days of layoff and years of education 121,81,251\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_pca)\n",
    "df['target'] = pd.Series(y)\n",
    "\n",
    "fig = px.scatter_3d(df, x=121, y=100, z=251,color='target')  # days of layoff and years of education \n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'may2012data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
